{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "075b0926-250a-4765-b12f-bb897295a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e24e26-3bfe-4389-944d-410bee49f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14caaeb5-6e74-4c2e-a1d6-f2ed7b7401d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f9195d-5887-4024-a913-201d0383000b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b289e-17bc-4323-90a7-7a3b82f59db4",
   "metadata": {},
   "source": [
    "# Now lets understand the spacy and nltk in action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f42cf-6524-4392-bee4-dc9723240a5d",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da57c574-e502-41e6-8490-252a5e665841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab856786-8d75-448c-bd4d-370934d141b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing some random spacy vs nltk to show the difference between them.\n",
      "Spacy is object oriented and nltk is string processing library\n"
     ]
    }
   ],
   "source": [
    "#Loading the spaCy English Language Model \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# \"en_core_web_sm\" is a pre-trained small English model in spaCy which ncludes a tokenizer, part-of-speech (POS) tagger, named entity recognizer (NER), and dependency parser.\n",
    "\n",
    "doc = nlp(\"Doing some random spacy vs nltk to show the difference between them. Spacy is object oriented and nltk is string processing library\")\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cdc8e2-0721-4b79-b01f-8650bdd515da",
   "metadata": {},
   "source": [
    "### This is called the sentence tokenization in spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d49317c-8901-4a10-856c-48ed86488a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing\n",
      "some\n",
      "random\n",
      "spacy\n",
      "vs\n",
      "nltk\n",
      "to\n",
      "show\n",
      "the\n",
      "difference\n",
      "between\n",
      "them\n",
      ".\n",
      "Spacy\n",
      "is\n",
      "object\n",
      "oriented\n",
      "and\n",
      "nltk\n",
      "is\n",
      "string\n",
      "processing\n",
      "library\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    for word in sentence:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363fd413-4778-45d1-9af4-9c430e223db8",
   "metadata": {},
   "source": [
    "### And this is called the word tokenization with the use of spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3055579-7dbd-4d04-b929-412e80a464dc",
   "metadata": {},
   "source": [
    "## nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9b335df-fffa-4b78-9413-ed7fb950da88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/satishadhikari/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "#nltk.download(\"punkt\") → Downloads the Punkt tokenizer, which is used for sentence and word tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5353d-76fc-48c1-8a61-13c7a105d06e",
   "metadata": {},
   "source": [
    "### sentence tokenizer using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e90abc6-470d-4e2b-a55e-5b4ca0086347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Doing some random spacy vs nltk to show the difference between them.',\n",
       " 'Spacy is object oriented and nltk is string processing library']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sent_tokenize(\"Doing some random spacy vs nltk to show the difference between them. Spacy is object oriented and nltk is string processing library\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc47d47c-bc69-40e6-a597-c73d5aec7e5e",
   "metadata": {},
   "source": [
    "### word tokenizer using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92b29357-0c61-4168-83ac-6f21134a1f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Doing',\n",
       " 'some',\n",
       " 'random',\n",
       " 'spacy',\n",
       " 'vs',\n",
       " 'nltk',\n",
       " 'to',\n",
       " 'show',\n",
       " 'the',\n",
       " 'difference',\n",
       " 'between',\n",
       " 'them',\n",
       " '.',\n",
       " 'Spacy',\n",
       " 'is',\n",
       " 'object',\n",
       " 'oriented',\n",
       " 'and',\n",
       " 'nltk',\n",
       " 'is',\n",
       " 'string',\n",
       " 'processing',\n",
       " 'library']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_tokenize(\"Doing some random spacy vs nltk to show the difference between them. Spacy is object oriented and nltk is string processing library\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe180ab-4c2e-4d1b-a3c2-9c084b72b671",
   "metadata": {},
   "source": [
    "# Let's go deeper with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d26ba777-4b14-4c13-8a95-4a310d78326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a633339a-e028-4ff0-92be-aae4ffd4fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "#creating a blank english language component\n",
    "#spacy language model for English\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9ded879-091e-4618-87fd-5ba9c8dd365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('''\"Dr. X has consulted me to visit the hospital for the time interval of 6 months. But I don't seem to obey.\"''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2a1339c-c524-4258-b66a-4140ef13b0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "Dr.\n",
      "X\n",
      "has\n",
      "consulted\n",
      "me\n",
      "to\n",
      "visit\n",
      "the\n",
      "hospital\n",
      "for\n",
      "the\n",
      "time\n",
      "interval\n",
      "of\n",
      "6\n",
      "months\n",
      ".\n",
      "But\n",
      "I\n",
      "do\n",
      "n't\n",
      "seem\n",
      "to\n",
      "obey\n",
      ".\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "704f40bf-4a7d-438e-a81a-2ab9826ec0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a08f52a-cd94-483d-b48c-b201829857b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dr. X has consulted me to"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0:5] \n",
    "#In NLP sometimes we need a span just like how we do index slicing in python. Span is nothing but a substring of a given string or slice of tokens in a document\n",
    "\n",
    "span = doc[0:7]\n",
    "span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e5fed83-20df-4ce3-8aa0-f134b4422514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dr. X has consulted me to visit the hospital for the time interval of 6 months. But I don't seem to obey."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5c519a9-8402-4a1e-abd2-95d33d8e0ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "881dab1d-d77a-4258-986c-05256bc59793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c242b525-b4d7-4e8c-b076-2a7c5a1e07a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "870dd689-1d56-4e3a-a5a9-68c8e8e5201a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(span)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596bbc09-9af9-47b4-a2ca-18825199292a",
   "metadata": {},
   "source": [
    "## Token Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93313739-d548-419c-8a0f-0c5e029135f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "have"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = nlp(\"I have 1$ in my pocket\")\n",
    "token1 = doc1[1]\n",
    "token1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8af6789-658c-4225-afe1-e66d9866475d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_dep',\n",
       " 'has_extension',\n",
       " 'has_head',\n",
       " 'has_morph',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'iob_strings',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_end',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'morph',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'set_morph',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(token1)    \n",
    "#this gives all the methods of the class Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9528fc9-e14e-4751-aff8-23b6b4e35ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca653bdd-cfc4-4ea7-a4af-789781855fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token1.is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f19306d-0fcc-41ab-8eb4-a2379af8ecac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token1.is_lower      #shows that the token1 which has the value 'have' is in a lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07c75268-c088-4ed0-b2b0-ab5375c7b0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token1.is_alpha        #shows token 1 is an alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19cf4bd7-1e78-4d80-8f76-e318bb469304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token0  = doc[0]\n",
    "token0.is_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59680c76-36e8-4444-ac24-8af6c32fb33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2 = doc[2]\n",
    "token2.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ac81d1a-0c63-4386-9320-3a922c24dba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token3 = doc1[3]\n",
    "token3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c8690b7-70c0-469e-944d-a076183bec14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token3.is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b630a73-b926-43c0-a356-50009cf7cc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ==> index:  0 is_alpha: True is_punct; False like_num: False is_currency: False\n",
      "have ==> index:  1 is_alpha: True is_punct; False like_num: False is_currency: False\n",
      "1 ==> index:  2 is_alpha: False is_punct; False like_num: True is_currency: False\n",
      "$ ==> index:  3 is_alpha: False is_punct; False like_num: False is_currency: True\n",
      "in ==> index:  4 is_alpha: True is_punct; False like_num: False is_currency: False\n",
      "my ==> index:  5 is_alpha: True is_punct; False like_num: False is_currency: False\n",
      "pocket ==> index:  6 is_alpha: True is_punct; False like_num: False is_currency: False\n"
     ]
    }
   ],
   "source": [
    "for x in doc1:\n",
    "    print(x , '==>', 'index: ', x.i, 'is_alpha:', x.is_alpha,\n",
    "          'is_punct;', x.is_punct,\n",
    "          'like_num:', x.like_num,\n",
    "          'is_currency:', x.is_currency,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9993ddc-55b9-47d6-b627-943e4bf89b39",
   "metadata": {},
   "source": [
    "### We made the use of regular expression for extracting required texts, emails, phone numbers from the big bulk of text. But lets use spacy to do the same task because it is much powerful and convenient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08cb4723-5dfc-40a4-b43a-1767c7d412ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'satish: Hello,I need the info of my order # 826398312 satish: I got an issue with my order number 826398312 satish: My order 826398312 is having an issue, I was charged 300$ when online it says 280$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68feee11-c939-4b89-b7c4-42dac8b6a48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['826398312', '826398312', '826398312', '300', '280']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2 = nlp(text)\n",
    "number = [] \n",
    "for token in doc2:\n",
    "    if token.like_num:\n",
    "       number.append(token.text)\n",
    "number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d834a-526b-4021-8afb-06fefa6df06c",
   "metadata": {},
   "source": [
    "## Customize Tokenization Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "524731c2-1bb1-49bc-aac8-d7846bfd0504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imma', 'do', 'this', 'task', 'now']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc9 = nlp('imma do this task now ')\n",
    "tokens = [token.text for token in doc9]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc31dcdb-9865-4bf6-87b8-b9e9609cd0a8",
   "metadata": {},
   "source": [
    "## What if we want to split the slang imma ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be92f539-4b6d-4647-8852-9673df4254ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbold import ORTH\n",
    "nlp.tokenizer.add_special_case(\"imma\", [\n",
    "    {ORTH : \"im\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
